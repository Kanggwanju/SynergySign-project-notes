# [SignBell 프로젝트] 2025-10-06 회고록

---

## 📝 작업 개요

* **작업일**: 2025.10.06
* **회고 작성자**: 강관주
* **팀 작업**: 모델별 최종 테스트 결과 공유 및 데이터셋 개선 전략 수립
* **개인 작업**: 5가지 LSTM 모델 테스트 및 3D 좌표 방식 적용 실험

---

## 👥 팀 미팅 및 작업

### 1. 모델별 최종 테스트 결과 공유 및 문제점 진단

저녁 미팅을 통해 각자 진행했던 AI 모델들의 최종 테스트 결과를 공유했습니다. 안타깝게도 모든 모델이 학습 데이터를 제대로 일반화하지 못하는 공통적인 문제에 부딪혔음을 확인했습니다.

* **강관주**: 5가지 LSTM 기반 모델 테스트 결과, 대부분 **과적합(Overfitting)**이 발생하거나 실제 테스트 정확도가 40%에 그치는 등 성능 확보에 어려움을 겪음.
    * v1: 간단한 LSTM 모델 - 학습 정확도 자체가 낮음
    * v2: Bidirectional LSTM + Attention (15배 증강) - 100% 정확도로 심각한 과적합 발생 (증강 전 Train/Test 분리 실수)
    * v3: v2 개선 (Attention 제거, Train/Test 분리 후 증강) - 검증 100%이나 실제 정확도 40%
    * v4: CNN + BiLSTM 하이브리드 - 성능 극히 불량
    * v5: K-Fold 교차 검증 + L2 정규화 + Dropout 강화 - 평균 82% 검증 정확도이나 실제 정확도 40%
* **백승현**: 1D CNN, Multi-Head Attention, 3D 좌표, 델타 데이터 등 가장 다채로운 시도를 했으나, 유사한 동작을 구분하지 못하거나 모델이 불안정해지는 문제 발생.
* **고동현**: Transformer 모델의 검증 정확도를 76%까지 확보했으나, 테스트 결과 이는 수어 동작이 아닌 **배경 등 부가 정보에 과적합된 '가짜 정확도'**임을 증명함.

공통적으로 '무한' 단어 학습에 어려움이 있었고, 이는 데이터셋 자체의 문제일 수 있다는 결론에 도달했습니다.

### 2. 향후 계획 및 결정 사항

개별 모델의 문제가 아닌, 데이터셋의 근본적인 한계라는 공감대를 형성하고 다음과 같이 구체적인 액션 플랜을 수립했습니다.

1.  **데이터셋 변경**: 문제가 되었던 '무한' 단어를 제외.
2.  **신규 데이터 추가**: '무한'을 대체할 **'기쁨', '인사', '안녕'** 3개 단어를 새로 추가하여 총 7개 단어로 데이터셋을 재구성하기로 결정.
3.  **데이터 추출 방식 통일**: 백승현 님이 공유한 **3D 좌표 추출 방식**을 표준으로 삼아 모든 모델에 공통적으로 적용하기로 함.

---

## 👨‍💻 개인 작업

### 1. 5가지 LSTM 모델 테스트 및 결과 분석

* **진행 내용**: 데드라인까지 다양한 LSTM 기반 모델 변형을 시도하며 최적의 성능을 찾기 위해 노력했습니다.

#### v1: 간단한 LSTM 모델
* LSTM(64) → Dropout → LSTM(32) → Dropout → Dense(5)
* 결과: 학습 정확도 자체가 낮아 개선 필요성 확인

#### v2: Bidirectional LSTM + Attention (15배 증강)
* 양방향 학습과 Attention 메커니즘 도입
* **치명적 문제**: Train/Test 분리 전에 증강하여 데이터 유출 발생
* 결과: 검증 100%, 테스트 100%로 심각한 과적합 발생
* 시사점: 같은 원본에서 파생된 증강 데이터가 Train/Test 양쪽에 포함되어 모델이 암기함

#### v3: v2 개선 (Attention 제거, Train/Test 분리 후 증강)
* 파라미터 수 감소 (438K → 135K)
* Train/Test 분리 후 Train만 6배 증강
* 결과: 검증 정확도 100%, 실제 테스트 40%
* 문제점: '무한' 편향 (대부분을 무한으로 예측), '월세' 인식 불가

#### v4: CNN + BiLSTM 하이브리드
* CNN으로 공간적 특징 추출 후 BiLSTM으로 시계열 학습
* 결과: 성능이 극히 불량하여 자세한 분석 생략

#### v5: K-Fold 교차 검증 + L2 정규화 + Dropout 강화
* v3 기반, 5-Fold 교차 검증 도입
* L2 정규화(0.001), Dropout 0.5→0.6으로 증가
* 결과:
    - 평균 검증 정확도 82.02% ± 3.86%
    - 가장 높은 Fold: 86.36%
    - **실제 테스트 정확도: 40% (2/5)**
* 시사점: 검증 정확도는 높지만 실제 성능은 여전히 낮음, 데이터 부족이 근본 원인

### 2. 백승현 님의 3D 좌표 추출 방식 적용

* **진행 내용**: 저녁 미팅 후 백승현 님이 공유한 3D 좌표 추출 방식을 기존 모델들에 적용하여 실험했습니다.
* **기대감**: 수어는 연속적이고 입체적인 동작이므로, 3D 좌표가 2D보다 더 풍부한 정보를 담을 수 있을 것으로 기대했습니다.
* **결과**:
    - 일부 모델에서 약간의 성능 향상이 관찰되었습니다.
    - 여전히 만족스러운 수준에는 도달하지 못했지만, 올바른 방향이라는 확신을 얻었습니다.
* **성찰**: 그동안 모델 구조와 하이퍼파라미터에만 집중했는데, 좌표 추출 방식을 간과했던 것이 아쉬웠습니다. 하지만 이제 새로운 가능성을 발견한 것 같아 희망적이었습니다.

---

## 🤔 느낀점

> 오늘은 프로젝트의 중요한 전환점이 된 날이었습니다. 10월 6일이 데드라인이었고, 그동안 각자 최선을 다해 모델을 개선하려 노력했지만, 미팅에서 결과를 공유했을 때 모두가 비슷한 벽에 부딪혔다는 것을 알게 되었습니다. 처음에는 좌절감이 들었지만, 동시에 '이것은 내 모델만의 문제가 아니라 데이터셋 자체의 문제구나'라는 깨달음을 얻었습니다.
>
> 특히 백승현 님이 3D 좌표 추출 방식을 공유했을 때, 희망이 보이기 시작했습니다. 수어는 본질적으로 3차원 공간에서 일어나는 연속적인 동작이기 때문에, 3D 좌표가 2D보다 훨씬 적합하다는 생각이 들었습니다. 그동안 모델 아키텍처와 하이퍼파라미터 튜닝에만 집중했는데, 가장 기본적인 입력 데이터 형식을 간과했던 것이 조금 아쉬웠지만, 지금이라도 발견한 것이 다행이라고 생각했습니다.
>
> '무한' 단어를 제외하고 새로운 단어들을 추가하기로 한 결정도 잘했다고 생각합니다. 5가지 모델을 테스트하면서 공통적으로 '무한'이 문제였다는 것을 확인했고, 이는 단순히 모델의 문제가 아니라 해당 단어 자체의 특성이나 데이터 품질 문제일 가능성이 높았습니다.
>
> 10월 6일 데드라인이 지났지만, 팀이 프로젝트를 계속 진행하기로 결정한 것이 정말 기뻤습니다. 그동안 우리가 쌓아온 노력들이 헛되지 않았고, 3D 좌표 방식이라는 새로운 돌파구를 찾았기 때문에 성공 가능성이 더 높아졌다고 느꼈습니다. 데드라인의 압박 속에서도 포기하지 않고 계속 도전할 수 있다는 것이 다행이었고, 팀원들 모두가 같은 문제를 공유하며 함께 해결책을 찾아가는 과정이 든든했습니다.

---

## ✅ 다음 계획

* **신규 단어 영상 촬영**: '기쁨', '인사', '안녕' 각 5개 이상 영상 촬영
* **3D 좌표 추출 방식 전면 적용**: 모든 데이터에 대해 3D 좌표 추출 방식으로 전환
* **7개 단어 데이터셋 재구성**: '무한' 제외, 신규 3개 단어 포함
* **모델 재학습 및 테스트**: 변경된 데이터셋과 3D 좌표로 모델 성능 재평가