# [SignBell 프로젝트] 2025-10-05 회고록

---

## 📝 작업 개요

* **작업일**: 2025.10.05
* **회고 작성자**: 강관주
* **팀 작업**: 자체 촬영 데이터 기반 모델 학습 전략 구체화 및 리스크 관리 계획 수립
* **개인 작업**: 팀원 촬영 데이터 통합 학습 및 LSTM 하이퍼파라미터 튜닝

---

## 👥 팀 미팅 및 작업

### 1. 자체 데이터 기반 모델 학습 전략 회의

* **진행 내용**: 팀원들이 직접 촬영한 고품질 영상 데이터를 기반으로 모델 학습을 진행했을 때, 기존 API 데이터만 사용했을 때보다 성능이 눈에 띄게 향상되었음을 확인하고 공유했습니다.
* **결정 사항**:
    1.  **주요 데이터 활용**: 성능 향상이 검증된 **자체 촬영 영상**을 핵심 학습 데이터로 사용하기로 확정했습니다.
    2.  **모델 다각화**: 최적의 성능을 내는 모델을 찾기 위해 **LSTM, CNN, 어텐션(Attention)** 등 다양한 아키텍처를 병렬로 테스트하여 비교 분석하기로 했습니다.
    3.  **리스크 관리 (Contingency Plan)**: 10월 6일까지 모델 구현에서 유의미한 결과가 도출되지 않을 경우를 대비하여, 프로젝트 주제를 변경하는 차선책까지 열어두고 논의하기로 했습니다.

### 2. 역할 분담 (Action Items)

* **AI 모델 학습 및 테스트**: 백승현, 강관주, 고동현 (~10/6)
* **서비스 와이어프레임 초안**: 송민재

---

## 👨‍💻 개인 작업

### 1. 팀원 촬영 데이터 통합 및 모델 학습

* **진행 내용**:
    * 팀원들이 촬영한 영상 데이터를 수집하여 통합했습니다.
    * 총 111개의 원본 시퀀스 데이터(5개 단어 × 약 20개 영상)를 확보했습니다.
    * 데이터 부족 문제를 해결하기 위해 10배 증강을 적용하여 총 1,221개의 학습 데이터를 생성했습니다.
    * LSTM 모델을 활용하여 학습을 진행했습니다.

### 2. LSTM 하이퍼파라미터 튜닝

* **진행 내용**: 모델 성능을 개선하기 위해 다양한 하이퍼파라미터 조정을 시도했습니다.
    * **모델 구조**: LSTM(64) → Dropout → LSTM(32) → Dropout → Dense(5)
    * **데이터 증강**: 10배 증강 적용
    * **학습 설정**: 200 에포크, 배치 사이즈 등 조정
* **학습 결과**:
    * 테스트 정확도: **39.59%** (테스트 손실: 1.2139)
    * 예측 신뢰도: **25.29%** (가장 높은 확률)
    * 문제점:
        - Epoch 24-26에서 정확도가 37% 수준으로 상승했으나, Epoch 27에서 급격히 붕괴 (18%까지 하락)
        - 이후 회복되지 않고 불안정한 학습 양상을 보임
        - 모든 클래스의 확률이 비슷하게 분포 (21-25%)되어 의미 있는 패턴을 학습하지 못함

### 3. 문제 분석 및 개선 방향 모색

* **원인 분석**:
    1.  원본 데이터 111개가 너무 적어 증강만으로는 한계가 있음
    2.  모델이 과적합(overfitting)에서 학습 붕괴(collapse)로 이어짐
    3.  데이터 증강으로 생성된 합성 데이터가 실제 변동성을 충분히 반영하지 못함
* **시사점**: 단순히 데이터를 증강하는 것만으로는 부족하며, 더 많은 원본 데이터 확보나 모델 구조 개선이 필요함을 확인했습니다.

---

## 🤔 느낀점

> 팀원들이 바쁜 와중에도 촬영 가이드라인을 지키며 고품질 영상을 만들어준 덕분에 모델 학습을 진행할 수 있었습니다. 모두가 프로젝트에 집중하고 있고, 각자의 역할에 최선을 다하는 모습을 보며 팀워크가 더욱 돈독해지는 것을 느꼈습니다. 이런 분위기가 저에게도 더 열심히 해야겠다는 동기부여가 되었습니다.
>
> 하지만 학습 결과는 여전히 기대에 미치지 못했습니다. 39%의 정확도는 실용성이 없는 수준이고, 예측 신뢰도도 25% 수준으로 모델이 확신을 갖지 못하고 있습니다. 특히 Epoch 27에서 학습이 급격히 붕괴되는 것을 보며, 단순한 데이터 증강만으로는 한계가 있다는 것을 깨달았습니다.
>
> 10월 6일이 데드라인이라는 압박감이 있었지만, 오히려 명확한 마감이 있어서 더욱 집중할 수 있었습니다. 만약 내일까지 의미 있는 결과를 내지 못한다면 주제를 변경해야 할 수도 있다는 현실이 무겁게 다가왔지만, 이는 어쩔 수 없는 선택이라고 생각했습니다. 하지만 지금은 그런 결과를 받아들이기보다, 팀원들과 함께 마지막까지 최선을 다해 이 주제를 성공시키고 싶다는 마음이 더 큽니다.

---

## ✅ 다음 계획

* **모델 구조 개선**: LSTM 외에 CNN, Attention 메커니즘 등 다른 아키텍처 시도
* **데이터 증강 기법 재검토**: 과도한 증강을 줄이고 원본 데이터의 특성을 보존하는 방향으로 조정
* **학습 안정성 개선**: Gradient clipping, 학습률 조정 등을 통해 학습 붕괴 방지
* **10월 6일 최종 평가**: 다양한 시도를 종합하여 프로젝트 지속 여부 최종 판단